{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "!pip install beautifulsoup4\n",
    "!pip install pyarrow\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import ssl\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import re\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Settings and Requests\n",
    "url = \"https://my.sa.ucsb.edu/public/curriculum/coursesearch.aspx\"\n",
    "data = requests.get(url)\n",
    "html = data.text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "session = requests.Session()\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Content-Type': 'application/x-www-form-urlencoded'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Obtaining all data from enire webpage\n",
    "classId = []\n",
    "year = []\n",
    "level = []\n",
    "\n",
    "for option in soup.find_all('option'):\n",
    "    classId.append(option['value'])\n",
    "\n",
    "year = classId[99:108]\n",
    "level = classId[-3:]\n",
    "classId = classId[:99]\n",
    "\n",
    "depAndQuarter = []\n",
    "\n",
    "for i in year:\n",
    "    for c in classId:\n",
    "        depAndQuarter.append([c, i])\n",
    "\n",
    "depAndQuarter = pd.DataFrame(depAndQuarter)\n",
    "depAndQuarter = depAndQuarter.rename(columns={0: \"department\", 1: \"quarter\"})\n",
    "depAndQuarter = depAndQuarter[~depAndQuarter.isin(['20251']).any(axis=1)]\n",
    "depAndQuarter = depAndQuarter.sort_values(by='department')\n",
    "departments = depAndQuarter.groupby(['department']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Loop through the dropdown choices\n",
    "\n",
    "data = pd.DataFrame(columns=['CourseID','Department','CourseTitle', 'Days','Time','Location'])\n",
    "\n",
    "for d in range(len(departments)):\n",
    "    for q in range(9):\n",
    "        response = session.get(url, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print(\"Error loading initial page:\", response.status_code)\n",
    "        else:\n",
    "            # Parse the initial HTML content\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "            # Extract the necessary hidden fields for the form submission\n",
    "            viewstate = soup.find(\"input\", {\"id\": \"__VIEWSTATE\"})['value']\n",
    "            viewstategenerator = soup.find(\"input\", {\"id\": \"__VIEWSTATEGENERATOR\"})['value']\n",
    "            eventvalidation = soup.find(\"input\", {\"id\": \"__EVENTVALIDATION\"})['value']\n",
    "        \n",
    "            # Prepare the form data\n",
    "            form_data = {\n",
    "                '__VIEWSTATE': viewstate,\n",
    "                '__VIEWSTATEGENERATOR': viewstategenerator,\n",
    "                '__EVENTVALIDATION': eventvalidation,\n",
    "                'ctl00$pageContent1$courseList': departments.index[d],  # Subject Area: Anthropology\n",
    "                'ctl00$pageContent1$quarterList': depAndQuarter.iloc[q, 1],  # Quarter: FALL 2024\n",
    "                'ctl00$pageContent1$dropDownCourseLevels': 'Undergraduate',  # Course Level: Undergraduate\n",
    "                'ctl00$pageContent1$searchButton.x': '0',  # Simulating button click coordinates\n",
    "                'ctl00$pageContent1$searchButton.y': '0'\n",
    "            }\n",
    "        \n",
    "            # Send the POST request with form data to simulate clicking the search button\n",
    "            response = session.post(url, data=form_data, headers=headers)\n",
    "        \n",
    "            # Check if the request was successful\n",
    "            if response.status_code == 200:\n",
    "                # Parse the response content using BeautifulSoup\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            else:\n",
    "                print(\"Error in POST request:\", response.status_code)\n",
    "\n",
    "        classList = soup.find_all(\"tr\", {\"class\": \"CourseInfoRow\"})\n",
    "\n",
    "        for c in range(len(classList)):\n",
    "            class_vec = []\n",
    "            course = classList[c]\n",
    "            class_vec.append(course.find_all(\"td\", {\"id\": \"CourseTitle\"})[0].contents[0].strip())\n",
    "            class_vec.append(departments.index[d])\n",
    "            class_vec.append(course.find_all(\"td\", {\"class\": \"PrimaryCourse\"})[0].find(\"span\").get_text().strip())\n",
    "            courseInfo = course.find_all(\"td\")[-5:-2]\n",
    "            for k in courseInfo:\n",
    "                class_vec.append(k.get_text().strip())\n",
    "            data.loc[len(data)] = class_vec\n",
    "    \n",
    "    print(departments.index[d], ' is department ', d, ' of ', len(departments), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Extracting departments\n",
    "\n",
    "dep_fullnames = pd.DataFrame(columns=[\"DepartmentCode\", \"DepartmentName\"])\n",
    "nameList = []\n",
    "for option in soup.find_all('option'):\n",
    "    nameList.append(option.text)\n",
    "for d in range(len(nameList)):\n",
    "    dep_fullnames.loc[d] = [nameList[d].split('-')[-1].strip(), nameList[d].split('-')[0].strip()]\n",
    "\n",
    "pd.DataFrame(dep_fullnames).to_csv(\"depNames.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Further Cleaning and Processing data.csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"cleanedData.csv\")\n",
    "df_lectures = df[df['CourseTitle'].notna()]\n",
    "locations_to_drop = ['T B A', '', 'ON   ASYNC', 'ON   LINE']\n",
    "df_lectures = df_lectures[~df_lectures.isin(locations_to_drop).any(axis=1)]\n",
    "room_df = pd.read_csv(\"roomToBuilding.csv\")\n",
    "coordinate_df = pd.read_csv(\"coordinates.csv\")\n",
    "data = pd.merge(df_lectures, room_df, on='Location')\n",
    "data = pd.merge(data, coordinate_df, on='Location')\n",
    "data.rename(columns={'Department': 'DepartmentCode'}, inplace=True)\n",
    "depNames = pd.read_csv(\"depNames.csv\")\n",
    "data = pd.merge(data, depNames, on='DepartmentCode', how='left')\n",
    "data = data.iloc[:, [0, 1, -1, 2, 3, 4, 5, 6, 7]]\n",
    "data['Longitude'] = \"\"\n",
    "data['Latitude'] = \"\"\n",
    "for r in range(len(data)):\n",
    "    coord = data.loc[r, \"coordinates\"].split(',')\n",
    "    data.at[r, 'Latitude'] = float(coord[0])\n",
    "    data.at[r, 'Longitude'] = float(coord[1])\n",
    "\n",
    "data = pd.read_csv(\"cleanedData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Creating and Processing Map Data\n",
    "mapData = pd.DataFrame(columns=['Department','building','Count','Percentage','Latitude','Longitude'])\n",
    "data.drop(['Location'], axis=1)\n",
    "coordinate_df['Latitude'] = \"\"\n",
    "coordinate_df['Longitude'] = \"\"\n",
    "for r in range(len(coordinate_df)):\n",
    "    coord = coordinate_df.loc[r, \"coordinates\"].split(',')\n",
    "    coordinate_df.at[r, 'Latitude'] = float(coord[0])\n",
    "    coordinate_df.at[r, 'Longitude'] = float(coord[1])\n",
    "\n",
    "for d in depNames['DepartmentName']:\n",
    "    df = data[data['DepartmentName'] == d]\n",
    "    mergeDf = pd.DataFrame()\n",
    "    lat = df.groupby(['Latitude']).count()\n",
    "    mergeDf['Latitude'] = pd.to_numeric(lat.index, errors='coerce')\n",
    "    mergeDf['Count'] = lat['CourseID'].values\n",
    "    mergeDf['Department'] = np.array(d)\n",
    "    mergeDf['Percentage'] = np.round(mergeDf['Count']/len(df)*100, 2)\n",
    "    mergeDf = mergeDf.merge(coordinate_df.loc[:, ['Latitude', 'Longitude', 'building']].drop_duplicates(subset=['Latitude', 'building']), \n",
    "                            on=\"Latitude\", how=\"left\")\n",
    "    mergeDf = mergeDf.iloc[:, [2, 5, 1, 3, 0, 4]]\n",
    "    #mergeDf['Blurb'] = \"\"\n",
    "    #for i in range(len(mergeDf)):\n",
    "    #    mergeDf.at[i, 'Blurb'] = \"Number of classes: \" + str(mergeDf.at[i, 'Count']) + \" (\" + str(mergeDf.at[i, 'Percentage'].round())+ \"2%)\"\n",
    "    mapData = pd.concat([mapData, mergeDf])\n",
    "\n",
    "mapData.rename(columns={'building': 'Building'}, inplace=True)\n",
    "mapData.to_csv(\"mapData.csv\", index=False) \n",
    "\n",
    "\n",
    "data = pd.read_csv(\"mapData.csv\")\n",
    "\n",
    "coordinate_df = pd.read_csv(\"buildingCoordinates.csv\")\n",
    "coordinate_df['Latitude'] = \"\"\n",
    "coordinate_df['Longitude'] = \"\"\n",
    "\n",
    "for r in range(len(coordinate_df)):\n",
    "    coord = coordinate_df.loc[r, \"coordinates\"].split(',')\n",
    "    coordinate_df.at[r, 'Latitude'] = float(coord[0])\n",
    "    coordinate_df.at[r, 'Longitude'] = float(coord[1])\n",
    "\n",
    "data = pd.merge(data, coordinate_df, on='Building')\n",
    "data.drop(['Latitude_x', 'Longitude_x'], axis=1, inplace=True)\n",
    "data.rename(columns={'Latitude_y': 'Latitude', 'Longitude_y': 'Longitude'}, inplace=True)\n",
    "data\n",
    "\n",
    "data.to_csv(\"newMapData.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Creating and processing Charts data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"cleanedData.csv\")\n",
    "depNames = data['DepartmentCode'].unique()\n",
    "\n",
    "daysData = pd.DataFrame()\n",
    "timesData = pd.DataFrame()\n",
    "\n",
    "for dep in depNames:\n",
    "    daysArr = []\n",
    "    timesArr = []\n",
    "    sub_df = data[data['DepartmentCode'] == dep]\n",
    "    for i, r in sub_df.iterrows():\n",
    "        x = str(r['Days']).split(' ')\n",
    "        if len(x[0])>1:\n",
    "            x = list(x[0])\n",
    "        for xx in x:\n",
    "            daysArr.append(xx)\n",
    "        timesArr.append(str(r['Time']).split('-')[0].strip().replace(\" \", \"\"))\n",
    "    daysCount = pd.DataFrame(pd.DataFrame(daysArr).groupby(0)[0].count())\n",
    "    daysCount['dep'] = np.full((len(daysCount),), dep)\n",
    "    daysCount.rename(columns={0: 'count'}, inplace=True)\n",
    "    daysCount.reset_index(inplace=True)\n",
    "    daysCount.rename(columns={0: 'days'}, inplace=True)\n",
    "    days_order = [\"M\", \"T\", \"W\", \"R\", \"F\"]\n",
    "    daysCount[\"days\"] = pd.Categorical(daysCount[\"days\"], categories=days_order, ordered=True)\n",
    "\n",
    "    # Sort the DataFrame\n",
    "    daysCount = daysCount.sort_values(\"days\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    daysData = pd.concat([daysData, daysCount])\n",
    "\n",
    "    timesCount = pd.DataFrame(pd.DataFrame(timesArr).groupby(0)[0].count())\n",
    "    timesCount['dep'] = np.full((len(timesCount),), dep)\n",
    "    timesCount.rename(columns={0: 'count'}, inplace=True)\n",
    "    timesCount.reset_index(inplace=True)\n",
    "    timesCount.rename(columns={0: 'time'}, inplace=True)\n",
    "    timesCount['time'] = pd.to_datetime(timesCount['time'], format='%I:%M%p')\n",
    "    timesCount = timesCount.sort_values(by='time')\n",
    "    timesCount['time'] = timesCount['time'].dt.strftime('%I:%M%p')\n",
    "    timesData = pd.concat([timesData, timesCount])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#timesData.to_csv('timesData.csv', index=False)\n",
    "daysData.to_csv('daysData.csv', index=False)\n",
    "daysData\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
